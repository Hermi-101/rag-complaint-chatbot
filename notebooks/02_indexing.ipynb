{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a61be2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter # Updated import\n",
    "from langchain_huggingface import HuggingFaceEmbeddings           # Updated import\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a25acc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the cleaned data from Task 1\n",
    "# Ensure the path is correct relative to where your notebook/script is\n",
    "df = pd.read_csv('../data/processed/filtered_complaints.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af78f4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling complete. Total rows: 15000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Her\\AppData\\Local\\Temp\\ipykernel_41136\\3686776440.py:7: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_sampled = df.groupby('Product', group_keys=False).apply(\n"
     ]
    }
   ],
   "source": [
    "# 2. Stratified Sampling (15,000 samples)\n",
    "# This ensures each product category is represented proportionally\n",
    "sample_size = 15000\n",
    "num_categories = df['Product'].nunique()\n",
    "samples_per_cat = sample_size // num_categories\n",
    "\n",
    "df_sampled = df.groupby('Product', group_keys=False).apply(\n",
    "    lambda x: x.sample(n=min(len(x), samples_per_cat), random_state=42)\n",
    ")\n",
    "\n",
    "print(f\"Sampling complete. Total rows: {len(df_sampled)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f431628a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Setup Chunking Strategy\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "\n",
    "# 4. Prepare Documents and Metadata\n",
    "documents = []\n",
    "metadatas = []\n",
    "\n",
    "for _, row in df_sampled.iterrows():\n",
    "    # We use the 'cleaned_narrative' created in Task 1\n",
    "    content = str(row['cleaned_narrative'])\n",
    "    chunks = text_splitter.split_text(content)\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        documents.append(chunk)\n",
    "        metadatas.append({\n",
    "            \"complaint_id\": str(row['Complaint ID']),\n",
    "            \"product\": row['Product']\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "844d6082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Initialize Embedding Model\n",
    "# This will download the model (approx 90MB) on the first run\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f62f3bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Vector store created with 42904 chunks.\n",
      "Location: c:\\Users\\Her\\Desktop\\Week_7\\rag-complaint-chatbot\\vector_store\n"
     ]
    }
   ],
   "source": [
    "# 6. Create and Save Vector Store\n",
    "import os\n",
    "vector_db_path = \"../vector_store\"\n",
    "\n",
    "# Ensure the directory exists\n",
    "if not os.path.exists(vector_db_path):\n",
    "    os.makedirs(vector_db_path)\n",
    "\n",
    "vector_db = Chroma.from_texts(\n",
    "    texts=documents,\n",
    "    embedding=embeddings,\n",
    "    metadatas=metadatas,\n",
    "    persist_directory=vector_db_path\n",
    ")\n",
    "\n",
    "print(f\"Success! Vector store created with {len(documents)} chunks.\")\n",
    "print(f\"Location: {os.path.abspath(vector_db_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65e61ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Result 1:\n",
      "Product: Checking or savings account\n",
      "Snippet: i called my financial institution immediately after i noticed several unauthorized purchases on my account while on the phone with the fraud departmen...\n",
      "\n",
      "Result 2:\n",
      "Product: Credit card\n",
      "Snippet: i had 2 unauthorized transactions on my card xxxx for xxxx and xxxx for xxxx xxxx the xxxx charge they took care of no problem but the xxxx charge the...\n"
     ]
    }
   ],
   "source": [
    "# Test Search\n",
    "test_query = \"problems with unauthorized transactions on my credit card\"\n",
    "results = vector_db.similarity_search(test_query, k=2)\n",
    "\n",
    "for i, doc in enumerate(results):\n",
    "    print(f\"\\nResult {i+1}:\")\n",
    "    print(f\"Product: {doc.metadata['product']}\")\n",
    "    print(f\"Snippet: {doc.page_content[:150]}...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
